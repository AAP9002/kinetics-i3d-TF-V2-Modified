{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune I3D Model for Bend Classification (LEFT, RIGHT, STRAIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import i3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHECKPOINT_PATHS_IMAGENET = {\n",
    "    \"rgb\": \"data/checkpoints/rgb_imagenet/model.ckpt\",\n",
    "    \"flow\": \"data/checkpoints/flow_imagenet/model.ckpt\",\n",
    "}\n",
    "\n",
    "# pre trained model checkpoints based on a \"joint\" model\n",
    "rgb_model_checkpoint = 'rgb'\n",
    "flow_model_checkpoint = 'flow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_checkpoint_name, num_classes):\n",
    "    model = i3d.InceptionI3d(num_classes=num_classes, spatial_squeeze=True, final_endpoint='Logits')\n",
    "\n",
    "    logging.info('Loading checkpoint for %s model', model_checkpoint_name)\n",
    "\n",
    "    tf.train.Checkpoint(model=model).restore(\n",
    "            _CHECKPOINT_PATHS_IMAGENET[model_checkpoint_name]\n",
    "    )\n",
    "\n",
    "    logging.info('Loaded checkpoint for %s model', model_checkpoint_name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "rgb_model = get_pretrained_model(rgb_model_checkpoint, 400)\n",
    "flow_model = get_pretrained_model(flow_model_checkpoint, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pre trained Model Loaded Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LABEL_MAP_PATH = \"data/label_map.txt\"\n",
    "_SAMPLE_PATHS = {\n",
    "    \"rgb\": \"data/v_CricketShot_g04_c01_rgb.npy\",\n",
    "    \"flow\": \"data/v_CricketShot_g04_c01_flow.npy\",\n",
    "}\n",
    "\n",
    "kinetics_classes = (\n",
    "        [x.strip() for x in open(_LABEL_MAP_PATH, encoding='utf-8')]\n",
    "    )\n",
    "\n",
    "num_classes = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_sample = tf.convert_to_tensor(np.load(_SAMPLE_PATHS[\"rgb\"]), dtype=tf.float32)\n",
    "logging.info(\"RGB sample loaded\")\n",
    "flow_sample = tf.convert_to_tensor(np.load(_SAMPLE_PATHS[\"flow\"]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of logits: 139.30215454101562\n",
      "\n",
      "Top classes and probabilities\n",
      "1.0 42.059036 playing cricket\n",
      "1.2958588e-09 21.594944 hurling (sport)\n",
      "3.377472e-10 20.250313 catching or throwing baseball\n",
      "1.4016727e-10 19.370852 catching or throwing softball\n",
      "9.852616e-11 19.018337 hitting baseball\n",
      "7.817063e-11 18.78691 playing tennis\n",
      "2.229546e-11 17.532398 playing kickball\n",
      "1.02992875e-11 16.76009 playing squash or racquetball\n",
      "5.1403977e-12 16.065145 shooting goal (soccer)\n",
      "3.8235903e-12 15.769205 hammer throw\n",
      "1.7346235e-12 14.978806 golf putting\n",
      "1.3726635e-12 14.744768 throwing discus\n",
      "1.2943969e-12 14.68606 javelin throw\n",
      "6.587782e-13 14.010647 pumping fist\n",
      "4.358122e-13 13.597471 shot put\n",
      "3.6078383e-13 13.408539 celebrating\n",
      "2.231552e-13 12.928127 applauding\n",
      "1.5636494e-13 12.572453 throwing ball\n",
      "1.4015313e-13 12.462996 dodgeball\n",
      "9.741567e-14 12.099247 tap dancing\n"
     ]
    }
   ],
   "source": [
    "rgb_logits, _ = rgb_model(rgb_sample)\n",
    "flow_logits, _ = flow_model(flow_sample)\n",
    "\n",
    "out_logits = rgb_logits + flow_logits\n",
    "\n",
    "out_predictions = tf.nn.softmax(out_logits)\n",
    "\n",
    "out_logits = out_logits[0]\n",
    "out_predictions = out_predictions[0]\n",
    "sorted_indices = np.argsort(out_predictions)[::-1]\n",
    "print(f\"Norm of logits: {np.linalg.norm(out_logits)}\")\n",
    "print(\"\\nTop classes and probabilities\")\n",
    "for index in sorted_indices[:20]:\n",
    "    print(out_predictions[index].numpy(), out_logits[index].numpy(), kinetics_classes[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
